# -*- coding: utf-8 -*-
"""36106-AT1-25589351-experiment-0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xmV7-zB2Cq90hSoa-k4hprGgsi77-b1B

# **Experiment Notebook**

---
## 0. Setup Environment

### 0.a Install Mandatory Packages

> Do not modify this code before running it
"""

# Commented out IPython magic to ensure Python compatibility.
# Do not modify this code

import os
import sys
from pathlib import Path

COURSE = "36106"
ASSIGNMENT = "AT1"
DATA = "data"

asgmt_path = f"{COURSE}/assignment/{ASSIGNMENT}"
root_path = "./"

print("###### Install required Python packages ######")
! pip install -r https://raw.githubusercontent.com/aso-uts/labs_datasets/main/36106-mlaa/requirements.txt

if os.getenv("COLAB_RELEASE_TAG"):

    from google.colab import drive
    from pathlib import Path

    print("\n###### Connect to personal Google Drive ######")
    gdrive_path = "/content/gdrive"
    drive.mount(gdrive_path)
    root_path = f"{gdrive_path}/MyDrive/"

print("\n###### Setting up folders ######")
folder_path = Path(f"{root_path}/{asgmt_path}/") / DATA
folder_path.mkdir(parents=True, exist_ok=True)
print(f"\nYou can now save your data files in: {folder_path}")

if os.getenv("COLAB_RELEASE_TAG"):
#     %cd {folder_path}

"""### 0.b Disable Warnings Messages

> Do not modify this code before running it
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

"""### 0.c Install Additional Packages

> If you are using additional packages, you need to install them here using the command: `! pip install <package_name>`
"""

# <Student to fill this section>
!apt-get update > /dev/null 2>&1
!apt-get install -y texlive texlive-xetex texlive-latex-extra pandoc > /dev/null 2>&1

"""### 0.d Import Packages"""

import ipywidgets as widgets
import pandas as pd
import numpy as np
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

"""---
## A. Project Description

"""

# @title Student Information
wgt_student_name = widgets.Text(
    value=None,
    placeholder='<student to fill this section>',
    description='Student Name:',
    style={'description_width': 'initial'},
    disabled=False
)

wgt_student_id = widgets.Text(
    value=None,
    placeholder='<student to fill this section>',
    description='Student Id:',
    style={'description_width': 'initial'},
    disabled=False
)

widgets.HBox([wgt_student_name, wgt_student_id])

# @title Experiment ID

wgt_experiment_id = widgets.BoundedIntText(
    value=0,
    min=0,
    max=3,
    step=1,
    description='Experiment ID:',
    style={'description_width': 'initial'},
    disabled=False
)
wgt_experiment_id

# @title Business Objective

wgt_business_objective = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Business Objective:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_business_objective

"""---
## B. Experiment Description
"""

# @title Experiment Hypothesis

wgt_experiment_hypothesis = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Experiment Hypothesis:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_experiment_hypothesis

# @title Experiment Expectations

wgt_experiment_expectations = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Experiment Expectations:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_experiment_expectations

"""---
## C. Data Understanding

### C.1   Load Datasets

> Do not change this code
"""

# Load training data
training_df = pd.read_csv(folder_path / "rental_training.csv")

# Load validation data
validation_df = pd.read_csv(folder_path / "rental_validation.csv")

# Load testing data
testing_df = pd.read_csv(folder_path / "rental_testing.csv")

"""### C.2 Explore Training Set

> You can add more cells in this section
"""

# <Student to fill this section>
training_df.head()

training_df.info()

training_df.describe()

sns.histplot(training_df['rent'], bins=30, kde=True, color="green")

sns.boxplot(y=training_df['rent'])

sns.scatterplot(x=training_df['floor_area'], y=training_df['rent'], color="purple")

sns.boxplot(x=training_df['number_of_bedrooms'], y=training_df['rent'])

sns.boxplot(x=training_df['suburb'], y=training_df['rent'], palette="coolwarm")

# @title Training Set Insights

wgt_eda_training_set_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Training Set Insights:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_eda_training_set_insights

"""### C.3 Explore Validation Set

> You can add more cells in this section
"""

# <Student to fill this section>
validation_df.head()

validation_df.info()

validation_df.describe()

sns.histplot(training_df['rent'], bins=30, kde=True, color="blue", label="Train", alpha=0.5)
sns.histplot(validation_df['rent'], bins=30, kde=True, color="red", label="Validation", alpha=0.5)
plt.legend()
plt.title("Rent Distribution: Train vs Validation")
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(10, 5))

sns.boxplot(x=training_df['furnished'], y=training_df['rent'], palette="Blues", ax=axes[0])
axes[0].set_title("Train: Furnished vs Rent")

sns.boxplot(x=validation_df['furnished'], y=validation_df['rent'], palette="Reds", ax=axes[1])
axes[1].set_title("Validation: Furnished vs Rent")

plt.tight_layout()
plt.show()

training_df['advertised_date'] = pd.to_datetime(training_df['advertised_date'])
validation_df['advertised_date'] = pd.to_datetime(validation_df['advertised_date'])

sns.lineplot(x=training_df['advertised_date'], y=training_df['rent'], label="Train", color="blue")
sns.lineplot(x=validation_df['advertised_date'], y=validation_df['rent'], label="Validation", color="red")
plt.title("Rent Trends Over Time: Train vs Validation")
plt.xticks(rotation=45)
plt.legend()
plt.show()

# @title Validation Set Insights

wgt_eda_validation_set_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Validation Set Insights:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_eda_validation_set_insights

"""### C.4 Explore Testing Set

> You can add more cells in this section
"""

# <Student to fill this section>
testing_df.head()

testing_df.info()

testing_df.describe()

plt.figure(figsize=(10, 6))

sns.histplot(training_df['rent'], bins=30, kde=True, color="blue", label="Train", alpha=0.5)
sns.histplot(validation_df['rent'], bins=30, kde=True, color="red", label="Validation", alpha=0.5)
sns.histplot(testing_df['rent'], bins=30, kde=True, color="green", label="Test", alpha=0.5)

plt.legend()
plt.title("Rent Distribution Across Train, Validation, and Test Sets")
plt.xlabel("Rent Price")
plt.ylabel("Density")
plt.show()

fig, axes = plt.subplots(1, 3, figsize=(10, 5), sharey=True)

sns.countplot(x=training_df['number_of_bedrooms'], palette="Blues", ax=axes[0])
axes[0].set_title("Train: Number of Bedrooms")

sns.countplot(x=validation_df['number_of_bedrooms'], palette="Reds", ax=axes[1])
axes[1].set_title("Validation: Number of Bedrooms")

sns.countplot(x=testing_df['number_of_bedrooms'], palette="Greens", ax=axes[2])
axes[2].set_title("Test: Number of Bedrooms")

plt.tight_layout()
plt.show()

# @title Testing Set Insights

wgt_eda_testing_set_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Testing Set Insights:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_eda_testing_set_insights

"""### C.5 Explore Target Variable

> Save the name of column used as the target variable and call it `target_name`

> You can add more cells in this section
"""

# <Student to fill this section>

target_name = 'rent'

plt.figure(figsize=(10, 6))

sns.histplot(training_df[target_name], bins=30, kde=True, color="blue", label="Train", alpha=0.5)
sns.histplot(validation_df[target_name], bins=30, kde=True, color="red", label="Validation", alpha=0.5)
sns.histplot(testing_df[target_name], bins=30, kde=True, color="green", label="Test", alpha=0.5)

plt.legend()
plt.title("Rent Distribution Across Train, Validation, and Test Sets")
plt.xlabel("Rent Price")
plt.ylabel("Density")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(x=training_df['floor_area'], y=training_df[target_name], hue=training_df['furnished'], alpha=0.6)
plt.xlabel('Area (sq ft)')
plt.ylabel('Rent Price')
plt.title('Rent vs. Area (Colored by Furnished Status)')
plt.legend(title='Furnished Status')
plt.show()

sns.lmplot(x='floor_area', y=target_name, data=training_df, height=6, aspect=1.2)
plt.title('Rent vs. Area with Regression Line')
plt.show()

# @title Target Variable Insights

wgt_eda_target_variable_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Target Variable Insights:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_eda_target_variable_insights

"""### C.6 Explore Feature of Interest

> You can add more cells in this section
"""

# <Student to fill this section>

top_levels = training_df['level'].value_counts().nlargest(20)
sns.barplot(x=top_levels.index, y=top_levels.values, palette="coolwarm")
plt.xlabel('Level')
plt.ylabel('Count')
plt.title('Top 20 Levels')
plt.xticks(rotation=45, ha='right')
plt.show()

sns.countplot(x=training_df['tenancy_preference'], palette="coolwarm")
plt.title('Tenancy preference')
plt.xticks(rotation=45, ha='right')
plt.show()

sns.countplot(x=training_df['point_of_contact'], palette="coolwarm")
plt.title('point of contact')
plt.xticks(rotation=45, ha='right')
plt.show()

# @title Feature Insights

wgt_eda_feature_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Insights:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_eda_feature_insights

"""---
## D. Feature Selection

### D.1 Approach 1
"""

# <Student to fill this section>
sns.barplot(x=training_df['suburb'], y=training_df['rent'], palette="coolwarm")

sns.barplot(x=training_df['furnished'], y=training_df['rent'], palette="coolwarm")

sns.pairplot(training_df[['rent', 'floor_area', 'number_of_bedrooms', 'number_of_bathrooms']])

# @title Feature Selection 1 Insights

wgt_feat_selection_1_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Selection 1:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_feat_selection_1_insights

"""### D.2 Approach 2"""

# <Student to fill this section>
sns.scatterplot(x=training_df['building_number'], y=training_df['rent'], color="purple")

sns.barplot(x=training_df['gender'], y=training_df['rent'], palette="coolwarm")

sns.barplot(x=training_df['prefix'], y=training_df['rent'], palette="coolwarm")

# @title Feature Selection 2 Insights

wgt_feat_selection_2_insights = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Selection 2:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_feat_selection_2_insights

"""## D.3 Final Selection of Features

> Save the names of selected features into a list called `features_list`
"""

# <Student to fill this section>

features_list = ['advertised_date','number_of_bedrooms','rent','floor_area','level','suburb','furnished','tenancy_preference','number_of_bathrooms']

# @title Feature Selection Explanation

wgt_feat_selection_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Selection Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_feat_selection_explanation

"""---
## E. Data Cleaning

### E.1 Copy Datasets

> Create copies of the datasets and called them `training_df_clean`, `validation_df_clean` and `testing_df_clean`

> Do not change this code
"""

# Create copy of datasets

training_df_clean = training_df[features_list].copy()
validation_df_clean = validation_df[features_list].copy()
testing_df_clean = testing_df[features_list].copy()

"""### E.2 Fixing "Data Types"

> Provide some explanations on why you believe it is important to fix this issue and its impacts

> You can add more cells in this section
"""

# <Student to fill this section>
training_df_clean.info()

validation_df_clean.info()

testing_df_clean.info()

training_df_clean[['level','suburb','furnished','tenancy_preference']] = training_df_clean[['level','suburb','furnished','tenancy_preference']].astype('string')
validation_df_clean[['level','suburb','furnished','tenancy_preference']] = validation_df_clean[['level','suburb','furnished','tenancy_preference']].astype('string')
testing_df_clean[['level','suburb','furnished','tenancy_preference']] = testing_df_clean[['level','suburb','furnished','tenancy_preference']].astype('string')

training_df_clean['advertised_date'] = pd.to_datetime(training_df_clean['advertised_date'], format='%Y-%m-%d')
validation_df_clean['advertised_date'] = pd.to_datetime(validation_df_clean['advertised_date'], format='%Y-%m-%d')
testing_df_clean['advertised_date'] = pd.to_datetime(testing_df_clean['advertised_date'], format='%Y-%m-%d')

training_df_clean.dtypes

validation_df_clean.dtypes

testing_df_clean.dtypes

# @title Data Cleaning 1 Explanation

wgt_data_cleaning_1_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Data Cleaning 1 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_data_cleaning_1_explanation

"""### E.3 Fixing "Missing Values & Duplicates"

> Provide some explanations on why you believe it is important to fix this issue and its impacts

> You can add more cells in this section
"""

# <Student to fill this section>
print(training_df_clean.isna().sum())
print(".............................")
print(validation_df_clean.isna().sum())
print(".............................")
print(testing_df_clean.isna().sum())

duplicate_count = training_df_clean.duplicated().sum()
duplicate_count1 = validation_df_clean.duplicated().sum()
duplicate_count2 = testing_df_clean.duplicated().sum()

print("training_df_clean duplicates: ", duplicate_count)
print("validation_df_clean duplicates: ", duplicate_count)
print("testing_df_clean duplicates: ", duplicate_count)

training_df_clean.drop_duplicates(inplace=True)
validation_df.drop_duplicates(inplace=True)
testing_df_clean.drop_duplicates(inplace=True)

duplicate_count = training_df_clean.duplicated().sum()
duplicate_count1 = validation_df_clean.duplicated().sum()
duplicate_count2 = testing_df_clean.duplicated().sum()

print("training_df_clean duplicates: ", duplicate_count)
print("validation_df_clean duplicates: ", duplicate_count)
print("testing_df_clean duplicates: ", duplicate_count)

# @title Data Cleaning 2 Explanation

wgt_data_cleaning_2_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Data Cleaning 1 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_data_cleaning_2_explanation

"""### E.4 Fixing "Outliers"

> Provide some explanations on why you believe it is important to fix this issue and its impacts

> You can add more cells in this section
"""

# <Student to fill this section>

Q1 = training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.25)
Q3 = training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.75)
IQR = Q3 - Q1

# Define outliers
outliers_iqr = training_df_clean[((training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']] < (Q1 - 1.5 * IQR)) |
                                  (training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']] > (Q3 + 1.5 * IQR))).any(axis=1)]

print(outliers_iqr)

# Create box plot for each numeric feature
sns.boxplot(data=training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']])
plt.show()

Q1 = training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.25)
Q3 = training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Apply clipping
training_df_clean['number_of_bedrooms'] = training_df_clean['number_of_bedrooms'].clip(lower=lower_bound['number_of_bedrooms'], upper=upper_bound['number_of_bedrooms'])
training_df_clean['rent'] = training_df_clean['rent'].clip(lower=lower_bound['rent'], upper=upper_bound['rent'])
training_df_clean['floor_area'] = training_df_clean['floor_area'].clip(lower=lower_bound['floor_area'], upper=upper_bound['floor_area'])
training_df_clean['number_of_bathrooms'] = training_df_clean['number_of_bathrooms'].clip(lower=lower_bound['number_of_bathrooms'], upper=upper_bound['number_of_bathrooms'])

# Create box plot for each numeric feature
sns.boxplot(data=training_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']])
plt.show()

Q1 = validation_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.25)
Q3 = validation_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Apply clipping
validation_df_clean['number_of_bedrooms'] = validation_df_clean['number_of_bedrooms'].clip(lower=lower_bound['number_of_bedrooms'], upper=upper_bound['number_of_bedrooms'])
validation_df_clean['rent'] = validation_df_clean['rent'].clip(lower=lower_bound['rent'], upper=upper_bound['rent'])
validation_df_clean['floor_area'] = validation_df_clean['floor_area'].clip(lower=lower_bound['floor_area'], upper=upper_bound['floor_area'])
validation_df_clean['number_of_bathrooms'] = validation_df_clean['number_of_bathrooms'].clip(lower=lower_bound['number_of_bathrooms'], upper=upper_bound['number_of_bathrooms'])

# Create box plot for each numeric feature
sns.boxplot(data=validation_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']])
plt.show()

Q1 = testing_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.25)
Q3 = testing_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Apply clipping
testing_df_clean['number_of_bedrooms'] = testing_df_clean['number_of_bedrooms'].clip(lower=lower_bound['number_of_bedrooms'], upper=upper_bound['number_of_bedrooms'])
testing_df_clean['rent'] = testing_df_clean['rent'].clip(lower=lower_bound['rent'], upper=upper_bound['rent'])
testing_df_clean['floor_area'] = testing_df_clean['floor_area'].clip(lower=lower_bound['floor_area'], upper=upper_bound['floor_area'])
testing_df_clean['number_of_bathrooms'] = testing_df_clean['number_of_bathrooms'].clip(lower=lower_bound['number_of_bathrooms'], upper=upper_bound['number_of_bathrooms'])

# Create box plot for each numeric feature
sns.boxplot(data=testing_df_clean[['number_of_bedrooms', 'rent', 'floor_area', 'number_of_bathrooms']])
plt.show()

# @title Data Cleaning 3 Explanation

wgt_data_cleaning_3_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Data Cleaning 3 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_data_cleaning_3_explanation

"""---
## F. Feature Engineering

### F.1 Copy Datasets

> Create copies of the datasets and called them `training_df_eng`, `validation_df_eng` and `testing_df_eng`

> Do not change this code
"""

# Create copy of datasets

training_df_eng = training_df_clean.copy()
validation_df_eng = validation_df_clean.copy()
testing_df_eng = testing_df_clean.copy()

"""### F.2 New Feature "month"

> Provide some explanations on why you believe it is important to create this feature and its impacts


"""

# <Student to fill this section>
training_df_eng['month'] = training_df_eng['advertised_date'].dt.month
validation_df_eng['month'] = validation_df_eng['advertised_date'].dt.month
testing_df_eng['month'] = testing_df_eng['advertised_date'].dt.month

training_df_eng.drop('advertised_date', axis=1, inplace=True)
validation_df_eng.drop('advertised_date', axis=1, inplace=True)
testing_df_eng.drop('advertised_date', axis=1, inplace=True)

# @title Feature Engineering 1 Explanation

wgt_feature_engineering_1_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Engineering 1 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_feature_engineering_1_explanation

training_df_eng.head()

"""### F.3 New Feature "level_numerator"

> Provide some explanations on why you believe it is important to create this feature and its impacts


"""

# <Student to fill this section>
training_df_eng['level'].value_counts()

training_df_eng[['level_numerator', 'level_denominator']] = training_df_eng['level'].str.split(' out of ', expand=True)

training_df_eng['level_numerator'] = training_df_eng['level_numerator'].replace('Ground', '0')
training_df_eng['level_numerator'] = training_df_eng['level_numerator'].replace('Lower Basement', '-2')
training_df_eng['level_numerator'] = training_df_eng['level_numerator'].replace('Upper Basement', '-1')
training_df_eng['level_denominator'] = training_df_eng['level_denominator'].fillna('1')

training_df_eng['level_numerator'] = training_df_eng['level_numerator'].astype(int)
training_df_eng['level_denominator'] = training_df_eng['level_denominator'].astype(int)

validation_df_eng[['level_numerator', 'level_denominator']] = validation_df_eng['level'].str.split(' out of ', expand=True)

validation_df_eng['level_numerator'] = validation_df_eng['level_numerator'].replace('Ground', '0')
validation_df_eng['level_numerator'] = validation_df_eng['level_numerator'].replace('Lower Basement', '-2')
validation_df_eng['level_numerator'] = validation_df_eng['level_numerator'].replace('Upper Basement', '-1')
validation_df_eng['level_denominator'] = validation_df_eng['level_denominator'].fillna('1')

validation_df_eng['level_numerator'] = validation_df_eng['level_numerator'].astype(int)
validation_df_eng['level_denominator'] = validation_df_eng['level_denominator'].astype(int)

testing_df_eng[['level_numerator', 'level_denominator']] = testing_df_eng['level'].str.split(' out of ', expand=True)

testing_df_eng['level_numerator'] = testing_df_eng['level_numerator'].replace('Ground', '0')
testing_df_eng['level_numerator'] = testing_df_eng['level_numerator'].replace('Lower Basement', '-2')
testing_df_eng['level_numerator'] = testing_df_eng['level_numerator'].replace('Upper Basement', '-1')
testing_df_eng['level_denominator'] = testing_df_eng['level_denominator'].fillna('1')

testing_df_eng['level_numerator'] = testing_df_eng['level_numerator'].astype(int)
testing_df_eng['level_denominator'] = testing_df_eng['level_denominator'].astype(int)

# @title Feature Engineering 2 Explanation

wgt_feature_engineering_2_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Engineering 2 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_feature_engineering_2_explanation

"""### F.4 New Feature "level_ratio"

> Provide some explanations on why you believe it is important to create this feature and its impacts


"""

# <Student to fill this section>
training_df_eng['level_ratio'] = training_df_eng['level_numerator'] / training_df_eng['level_denominator']

training_df_eng.drop(['level_denominator', 'level'], axis=1, inplace=True)

validation_df_eng['level_ratio'] = validation_df_eng['level_numerator'] / validation_df_eng['level_denominator']

validation_df_eng.drop(['level_denominator', 'level'], axis=1, inplace=True)

testing_df_eng['level_ratio'] = testing_df_eng['level_numerator'] / testing_df_eng['level_denominator']

testing_df_eng.drop(['level_denominator', 'level'], axis=1, inplace=True)

# @title Feature Engineering 3 Explanation

wgt_feature_engineering_3_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Feature Engineering 3 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_feature_engineering_3_explanation

"""---
## G. Data Preparation for Modeling

### G.1 Copy Datasets

> Create copies of the datasets and split them into X and y

> Do not change this code
"""

# Create copy of datasets

X_train = training_df_eng.copy()
X_val = validation_df_eng.copy()
X_test = testing_df_eng.copy()

y_train = X_train.pop(target_name)
y_val = X_val.pop(target_name)
y_test = X_test.pop(target_name)

"""### G.2 Data Transformation <put_name_here>

> Provide some explanations on why you believe it is important to perform this data transformation and its impacts

"""

# <Student to fill this section>

# One-Hot Encoding for 'tenancy_preference' and 'suburb'
df_dummies = pd.get_dummies(X_train[['tenancy_preference', 'suburb']])
df_dummies = df_dummies.astype(int)
X_train = pd.concat([X_train, df_dummies], axis=1)
X_train.drop(['tenancy_preference', 'suburb'], axis=1, inplace=True)

# One-Hot Encoding for 'tenancy_preference' and 'suburb'
df_dummies = pd.get_dummies(X_val[['tenancy_preference', 'suburb']])
df_dummies = df_dummies.astype(int)

X_val = pd.concat([X_val, df_dummies], axis=1)
X_val.drop(['tenancy_preference', 'suburb'], axis=1, inplace=True)

# One-Hot Encoding for 'tenancy_preference' and 'suburb'
df_dummies = pd.get_dummies(X_test[['tenancy_preference', 'suburb']])
df_dummies = df_dummies.astype(int)

X_test = pd.concat([X_test, df_dummies], axis=1)
X_test.drop(['tenancy_preference', 'suburb'], axis=1, inplace=True)

# @title Data Preparation 1 Explanation

wgt_data_preparation_1_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Data Preparation 1 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_data_preparation_1_explanation

"""### G.3 Data Transformation <put_name_here>

> Provide some explanations on why you believe it is important to perform this data transformation and its impacts

"""

# <Student to fill this section>

furnished_mapping = {
    'Furnished': 2,
    'Semi-Furnished': 1,
    'Unfurnished': 0
}

# Apply the mapping to the 'furnished' column
X_train['furnished_encoded'] = X_train['furnished'].map(furnished_mapping)

X_train.drop(['furnished'], axis=1, inplace=True)

# Apply the mapping to the 'furnished' column
X_val['furnished_encoded'] = X_val['furnished'].map(furnished_mapping)

X_val.drop(['furnished'], axis=1, inplace=True)

# Apply the mapping to the 'furnished' column
X_test['furnished_encoded'] = X_test['furnished'].map(furnished_mapping)

X_test.drop(['furnished'], axis=1, inplace=True)

# @title Data Preparation 2 Explanation

wgt_data_preparation_2_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Data Preparation 2 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_data_preparation_2_explanation

"""### G.4 Data Transformation <put_name_here>

> Provide some explanations on why you believe it is important to perform this data transformation and its impacts

"""

standard_scaler = StandardScaler()

column_names = X_train.columns.tolist()

X_train = pd.DataFrame(standard_scaler.fit_transform(X_train), columns=column_names)
X_val = pd.DataFrame(standard_scaler.transform(X_val), columns=column_names)
X_test = pd.DataFrame(standard_scaler.transform(X_test), columns=column_names)

# @title Data Preparation 3 Explanation

wgt_data_preparation_3_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Data Preparation 3 Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_data_preparation_3_explanation

"""---
## H. Save Datasets

> Do not change this code
"""

# Save training set

X_train.to_csv(folder_path / 'X_train.csv', index=False)
y_train.to_csv(folder_path / 'y_train.csv', index=False)

# Save validation set

X_val.to_csv(folder_path / 'X_val.csv', index=False)
y_val.to_csv(folder_path / 'y_val.csv', index=False)

# Save testing set

X_test.to_csv(folder_path / 'X_test.csv', index=False)
y_test.to_csv(folder_path / 'y_test.csv', index=False)

"""---
## I. Assess Baseline Model

### I.1 Generate Predictions with Baseline Model
"""

# <Student to fill this section>
from sklearn.dummy import DummyRegressor

base_reg = DummyRegressor(strategy='mean')
base_reg.fit(X_train, y_train)
y_train_preds = base_reg.predict(X_train)

"""### I.2 Selection of Performance Metrics

> Provide some explanations on why you believe the performance metrics you chose is appropriate

"""

# <Student to fill this section>

mse = mean_squared_error(y_train, y_train_preds)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_train, y_train_preds)
r2 = r2_score(y_train, y_train_preds)

print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2: {r2}")

# @title Performance Metrics Explanation

wgt_perf_metrics_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Performance Metrics Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_perf_metrics_explanation

"""### I.3 Baseline Model Performance

> Provide some explanations on model performance

"""

# <Student to fill this section>
(y_train_preds - y_train).sum()

# @title Performance Metrics Explanation

wgt_model_performance_explanation = widgets.Textarea(
    value=None,
    placeholder='<student to fill this section>',
    description='Model Performance Explanation:',
    disabled=False,
    style={'description_width': 'initial'},
    layout=widgets.Layout(height="100%", width="auto")
)
wgt_model_performance_explanation

# Clear metadata for all experiment notebooks
!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_0.ipynb" \
--ClearMetadataPreprocessor.enabled=True \
--ClearMetadataPreprocessor.clear_cell_metadata=True \
--ClearMetadataPreprocessor.clear_notebook_metadata=True \
--ClearOutputPreprocessor.enabled=False \
--inplace

!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_1.ipynb" \
--ClearMetadataPreprocessor.enabled=True \
--ClearMetadataPreprocessor.clear_cell_metadata=True \
--ClearMetadataPreprocessor.clear_notebook_metadata=True \
--ClearOutputPreprocessor.enabled=False \
--inplace

!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_2.ipynb" \
--ClearMetadataPreprocessor.enabled=True \
--ClearMetadataPreprocessor.clear_cell_metadata=True \
--ClearMetadataPreprocessor.clear_notebook_metadata=True \
--ClearOutputPreprocessor.enabled=False \
--inplace

!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_3.ipynb" \
--ClearMetadataPreprocessor.enabled=True \
--ClearMetadataPreprocessor.clear_cell_metadata=True \
--ClearMetadataPreprocessor.clear_notebook_metadata=True \
--ClearOutputPreprocessor.enabled=False \
--inplace

# Convert all notebooks to PDF
!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_0.ipynb" --to pdf
!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_1.ipynb" --to pdf
!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_2.ipynb" --to pdf
!jupyter nbconvert "/content/gdrive/MyDrive/Colab Notebooks/36106_25AU-AT1_25589351_experiment_3.ipynb" --to pdf